{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XOR/XNOR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWUnHo_pMwku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBcvFqx8M4yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array([[1, 1, 0],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 0],\n",
        "                [1, 1, 1],\n",
        "                [1, 0, 1],\n",
        "                [0, 1, 1],\n",
        "                [0, 0, 1]])\n",
        "y = np.array([1, 0, 0, 1, 0, 1, 1, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXgt5AYWOCaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We will be using the sigmoid activation in the net, so these two functions\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_back(a):\n",
        "    return np.multiply(a, 1-a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pJmE5sbOyRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(inputs = 3, outputs = 1, hidden  = 10):\n",
        "    #randomly initialise the weights\n",
        "    w1 = np.random.rand(hidden, inputs)\n",
        "    w2 = np.random.rand(outputs, hidden)\n",
        "    #set all thebiases to zero\n",
        "    b1 = np.zeros((1, hidden))\n",
        "    b2 = np.zeros((1, outputs))\n",
        "    return w1, w2, b1, b2\n",
        "\n",
        "def forward(x, w1, w2, b1, b2):\n",
        "    m1 = np.dot(x, w1.T) + b1\n",
        "    n1 = sigmoid(m1)\n",
        "    m2 = np.dot(n1, w2.T) + b2\n",
        "    n2 = sigmoid(m2)\n",
        "    return n1, n2\n",
        "\n",
        "def loss(n2, y):\n",
        "    #using the log loss here\n",
        "    m = len(y)\n",
        "    l = -1.0/m * np.sum(np.multiply(y, np.log(n2)) + np.multiply(1.0-y, np.log(1-n2)))\n",
        "    return l\n",
        "\n",
        "def backprop(x, y, n1, n2, w1, w2):\n",
        "    m = len(y)\n",
        "    da2 = -1.0 * (np.divide(y, n2)-np.divide(1-y, 1-n2))\n",
        "    dz2 = np.multiply(da2,sigmoid_back(n2))\n",
        "    dw2 = (1.0/m)*np.dot(dz2.T,n1) \n",
        "    db2 = (1.0/m)*np.sum(dz2)\n",
        "    da1 = np.dot(dz2,w2)\n",
        "    dz1 = np.multiply(da1,sigmoid_back(n1))\n",
        "    dw1 = (1.0/m)*np.dot(dz1.T,x) \n",
        "    db1 = (1.0/m)*np.sum(dz1)\n",
        "    return dw1, db1, dw2, db2\n",
        "\n",
        "def train(x, y, iterations = 10000, lr = 0.9):\n",
        "    #the main function\n",
        "    w1, w2, b1, b2 = initialize_weights()\n",
        "\n",
        "    for i in range(iterations):\n",
        "        n1, n2 = forward(x, w1, w2, b1, b2)\n",
        "        l = loss(n2, y)\n",
        "        dw1, db1, dw2, db2 = backprop(x, y, n1, n2, w1, w2)\n",
        "    \n",
        "        w1 = w1-lr*dw1\n",
        "        w2 = w2-lr*dw2\n",
        "        b1 = b1-lr*db1\n",
        "        b2 = b2-lr*db2\n",
        "\n",
        "        if i%1000 == 0:\n",
        "            print(\"iter -> \", i, \"loss -> \", l)\n",
        "        \n",
        "    return w1, w2, b1, b2, l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfbTUTAN4DO9",
        "colab_type": "code",
        "outputId": "8679a7fc-94d4-41d3-9a2b-63b237e0226d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#train the net\n",
        "w1, w2, b1, b2, l = train(X, y.reshape(-1, 1))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter ->  0 loss ->  1.4537381504378057\n",
            "iter ->  1000 loss ->  0.10561580895766443\n",
            "iter ->  2000 loss ->  0.007963015738439385\n",
            "iter ->  3000 loss ->  0.0037109356405404786\n",
            "iter ->  4000 loss ->  0.002374696772026392\n",
            "iter ->  5000 loss ->  0.001733238894018586\n",
            "iter ->  6000 loss ->  0.0013594276024655948\n",
            "iter ->  7000 loss ->  0.0011156866593421257\n",
            "iter ->  8000 loss ->  0.0009446282792504623\n",
            "iter ->  9000 loss ->  0.0008181780516422615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqxagav044_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the predict function\n",
        "def predict(x, w1, w2, b1, b2):\n",
        "    pred1, pred2 = forward(x, w1, w2, b1, b2)\n",
        "    #thresholding\n",
        "    if pred2 > 0.5:\n",
        "        pred = 1\n",
        "    else:\n",
        "        pred = 0\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPnXAOflAg1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}